<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>AI Image Video Generator</title>
  <style>
    body {
      background: #121212;
      color: white;
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
      user-select: none;
    }
    canvas {
      border: 2px solid white;
      margin-top: 20px;
      background: black;
    }
    input, button, select {
      margin: 10px 5px;
      padding: 10px 15px;
      font-size: 16px;
      background: #222;
      color: white;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    input[type=file] {
      padding: 5px;
    }
    button:hover {
      background: #444;
    }
  </style>
</head>
<body>
  <h1>✨ AI Image Video Generator (Crossfade + Audio + MP4 Export)</h1>

  <input type="file" id="imageInput" accept="image/*" multiple />
  <input type="file" id="audioInput" accept="audio/*" />
  <br />
  <button id="startBtn">▶️ Start & Record</button>
  <button id="stopBtn" disabled>⏹ Stop Recording</button>
  <a id="downloadBtn" style="display:none" download="ai-video.mp4">⬇️ Download MP4</a>
  <br />
  <select id="durationSelect" title="Duration per image (seconds)">
    <option value="2">2s per image</option>
    <option value="3" selected>3s per image</option>
    <option value="5">5s per image</option>
  </select>

  <canvas id="canvas" width="640" height="480"></canvas>

  <p id="status" style="margin-top: 15px; font-style: italic;"></p>

  <script src="https://cdn.jsdelivr.net/npm/@ffmpeg/ffmpeg@0.11.8/dist/ffmpeg.min.js"></script>

  <script>
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const imageInput = document.getElementById("imageInput");
    const audioInput = document.getElementById("audioInput");
    const startBtn = document.getElementById("startBtn");
    const stopBtn = document.getElementById("stopBtn");
    const downloadBtn = document.getElementById("downloadBtn");
    const durationSelect = document.getElementById("durationSelect");
    const statusText = document.getElementById("status");

    let images = [];
    let audioFile = null;
    let audioBuffer = null;
    let audioCtx = null;
    let sourceNode = null;
    let animationFrameId = null;
    let isRecording = false;
    let currentTime = 0;
    let crossfadeDuration = 1; // seconds for fade
    let durationPerImage = parseInt(durationSelect.value);
    let videoChunks = [];
    let ffmpeg;
    let recordingStartTime;
    let mediaRecorder;

    // Load images from files
    imageInput.addEventListener("change", async (e) => {
      const files = [...e.target.files];
      if (files.length === 0) {
        alert("Please select some images!");
        return;
      }
      statusText.textContent = "Loading images...";
      images = await Promise.all(files.map(file => loadImage(URL.createObjectURL(file))));
      statusText.textContent = `Loaded ${images.length} images`;
    });

    // Load audio
    audioInput.addEventListener("change", async (e) => {
      const file = e.target.files[0];
      if (!file) return;
      audioFile = file;
      statusText.textContent = "Loading audio...";
      if (!audioCtx) audioCtx = new AudioContext();
      const arrayBuffer = await file.arrayBuffer();
      audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      statusText.textContent = `Loaded audio: ${file.name}`;
    });

    // Load image helper
    function loadImage(src) {
      return new Promise((res) => {
        const img = new Image();
        img.crossOrigin = "anonymous";
        img.onload = () => res(img);
        img.onerror = () => {
          alert("Failed to load image: " + src);
          res(null);
        };
        img.src = src;
      });
    }

    // Clamp helper
    function clamp(val) {
      return Math.min(255, Math.max(0, val));
    }

    // Draw with crossfade
    function drawCrossfade(t) {
      if (images.length === 0) return;

      const totalDuration = durationPerImage;
      const fadeDur = crossfadeDuration;
      const currentImageIndex = Math.floor(t / totalDuration) % images.length;
      const nextImageIndex = (currentImageIndex + 1) % images.length;

      const timeInImage = t % totalDuration;

      let alphaCurrent = 1;
      let alphaNext = 0;

      if (timeInImage >= totalDuration - fadeDur) {
        alphaCurrent = (totalDuration - timeInImage) / fadeDur;
        alphaNext = 1 - alphaCurrent;
      }

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      drawImageScaled(images[currentImageIndex], alphaCurrent);
      drawImageScaled(images[nextImageIndex], alphaNext);
    }

    function drawImageScaled(img, alpha) {
      if (!img) return;
      const scale = Math.min(canvas.width / img.width, canvas.height / img.height);
      const x = (canvas.width - img.width * scale) / 2;
      const y = (canvas.height - img.height * scale) / 2;
      ctx.globalAlpha = alpha;
      ctx.drawImage(img, x, y, img.width * scale, img.height * scale);
      ctx.globalAlpha = 1;
    }

    function animate(time) {
      if (!recordingStartTime) recordingStartTime = time;
      currentTime = (time - recordingStartTime) / 1000;
      drawCrossfade(currentTime);
      animationFrameId = requestAnimationFrame(animate);
    }

    async function startRecording() {
      if (images.length === 0) return alert("Upload images first!");

      durationPerImage = parseInt(durationSelect.value);
      statusText.textContent = "Starting recording...";

      if (audioBuffer) {
        if (!audioCtx) audioCtx = new AudioContext();
        if (sourceNode) sourceNode.disconnect();

        sourceNode = audioCtx.createBufferSource();
        sourceNode.buffer = audioBuffer;
        sourceNode.connect(audioCtx.destination);
        sourceNode.start(0);
      }

      animationFrameId = requestAnimationFrame(animate);

      const canvasStream = canvas.captureStream(30);

      let finalStream;
      if (audioBuffer) {
        const dest = audioCtx.createMediaStreamDestination();
        sourceNode.connect(dest);
        finalStream = new MediaStream([
          ...canvasStream.getVideoTracks(),
          ...dest.stream.getAudioTracks(),
        ]);
      } else {
        finalStream = canvasStream;
      }

      if (!ffmpeg) {
        statusText.textContent = "Loading ffmpeg.wasm, please wait...";
        ffmpeg = FFmpeg.createFFmpeg({ log: true });
        await ffmpeg.load();
      }

      videoChunks = [];
      mediaRecorder = new MediaRecorder(finalStream, { mimeType: "video/webm; codecs=vp9" });

      mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) videoChunks.push(e.data);
      };

      mediaRecorder.onstop = async () => {
        statusText.textContent = "Encoding video to MP4...";

        const webmBlob = new Blob(videoChunks, { type: "video/webm" });
        const webmBuffer = await webmBlob.arrayBuffer();

        ffmpeg.FS("writeFile", "input.webm", new Uint8Array(webmBuffer));
        await ffmpeg.run(
          "-i", "input.webm",
          "-c:v", "libx264",
          "-preset", "fast",
          "-pix_fmt", "yuv420p",
          "-movflags", "faststart",
          "output.mp4"
        );

        const data = ffmpeg.FS("readFile", "output.mp4");
        const mp4Blob = new Blob([data.buffer], { type: "video/mp4" });

        downloadBtn.href = URL.createObjectURL(mp4Blob);
        downloadBtn.style.display = "inline-block";
        statusText.textContent = "Video ready! Click download.";
        stopBtn.disabled = true;
        startBtn.disabled = false;
      };

      mediaRecorder.start();
      startBtn.disabled = true;
      stopBtn.disabled = false;
      downloadBtn.style.display = "none";
      statusText.textContent = "Recording...";
      recordingStartTime = null;
      isRecording = true;
    }

    function stopRecording() {
      if (!isRecording) return;
      cancelAnimationFrame(animationFrameId);
      animationFrameId = null;

      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }

      if (sourceNode) {
        sourceNode.stop();
        sourceNode.disconnect();
        sourceNode = null;
      }

      if (audioCtx) {
        audioCtx.close();
        audioCtx = null;
      }

      statusText.textContent = "Recording stopped.";
      startBtn.disabled = false;
      stopBtn.disabled = true;
      isRecording = false;
    }

    startBtn.addEventListener("click", startRecording);
    stopBtn.addEventListener("click", stopRecording);
  </script>
</body>
</html>
